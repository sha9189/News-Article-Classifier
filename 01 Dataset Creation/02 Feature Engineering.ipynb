{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import wordnet\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"raw data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc_name  Category                                            Content\n",
       "0  001.txt  Business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1  002.txt  Business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2  003.txt  Business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3  004.txt  Business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4  005.txt  Business  Pernod takeover talk lifts Domecq\\n\\nShares in..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Category_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Category_codes\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...               0\n",
       "1  Dollar gains on Greenspan speech  The dollar h...               0\n",
       "2  Yukos unit buyer faces loan claim  The owners ...               0\n",
       "3  High fuel prices hit BA's profits  British Air...               0\n",
       "4  Pernod takeover talk lifts Domecq  Shares in U...               0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Content_parsed\", \"Doc_name\", \"Category\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### 1. Convert Everything To Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert everything to lowercase\n",
    "data[\"Content_parsed_1\"] = data[\"Content\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit\\n\\nquarterly profits at us media giant timewarner jumped 76% to $1.13bn (â£600m) for the three months to december, from $639m year-earlier.\\n\\nthe firm, which is now one of the biggest investors in google, benefited from sales of high-speed internet connections and higher advert sales. timewarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. its profits were buoyed by one-off gains which offset a profit dip at warner bros, and less users for aol.\\n\\ntime warner said on friday that it now owns 8% of search-engine google. but its own internet business, aol, had has mixed fortunes. it lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. however, the company said aol\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol\\'s existing customers for high-speed broadband. timewarner also has to restate 2000 and 2003 results following a probe by the us securities exchange commission (sec), which is close to concluding.\\n\\ntime warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. but its film division saw profits slump 27% to $284m, helped by box-office flops alexander and catwoman, a sharp contrast to year-earlier, when the third and final film in the lord of the rings trilogy boosted results. for the full-year, timewarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive richard parsons said. for 2005, timewarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\ntimewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators. it has already offered to pay $300m to settle charges, in a deal that is under review by the sec. the company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. it intends to adjust the way it accounts for a deal with german music publisher bertelsmann\\'s purchase of a stake in aol europe, which it had reported as advertising revenue. it will now book the sale of its stake in aol europe as a loss on the value of that stake.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0, \"Content_parsed_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handling Possesive Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possesive Pronouns\n",
    "data[\"Content_parsed_2\"] = data[\"Content_parsed_1\"].str.replace(\"'s\", \"\").str.replace(\"’s\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit\\n\\nquarterly profits at us media giant timewarner jumped 76% to $1.13bn (â£600m) for the three months to december, from $639m year-earlier.\\n\\nthe firm, which is now one of the biggest investors in google, benefited from sales of high-speed internet connections and higher advert sales. timewarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. its profits were buoyed by one-off gains which offset a profit dip at warner bros, and less users for aol.\\n\\ntime warner said on friday that it now owns 8% of search-engine google. but its own internet business, aol, had has mixed fortunes. it lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. however, the company said aol underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aol existing customers for high-speed broadband. timewarner also has to restate 2000 and 2003 results following a probe by the us securities exchange commission (sec), which is close to concluding.\\n\\ntime warner fourth quarter profits were slightly better than analysts\\' expectations. but its film division saw profits slump 27% to $284m, helped by box-office flops alexander and catwoman, a sharp contrast to year-earlier, when the third and final film in the lord of the rings trilogy boosted results. for the full-year, timewarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive richard parsons said. for 2005, timewarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\ntimewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators. it has already offered to pay $300m to settle charges, in a deal that is under review by the sec. the company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. it intends to adjust the way it accounts for a deal with german music publisher bertelsmann purchase of a stake in aol europe, which it had reported as advertising revenue. it will now book the sale of its stake in aol europe as a loss on the value of that stake.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Content_parsed_2\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of stop words extracted from https://gist.github.com/sebleier/554280\n",
    "stop_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words\n",
    "data[\"Content_parsed_3\"] = data['Content_parsed_2']\n",
    "data[\"Content_parsed_3\"] = data[\"Content_parsed_3\"].str.replace(\"’\", \"'\")\n",
    "for stop_word in stop_words:\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    data['Content_parsed_3'] = data['Content_parsed_3'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit\\n\\nquarterly profits   media giant timewarner jumped 76%  $1.13bn (â£600m)    months  december,  $639m year-earlier.\\n\\n firm,       biggest investors  google, benefited  sales  high-speed internet connections  higher advert sales. timewarner  fourth quarter sales rose 2%  $11.1bn  $10.9bn.  profits  buoyed  - gains  offset  profit dip  warner bros,   users  aol.\\n\\ntime warner   friday    owns 8%  search-engine google.    internet business, aol,   mixed fortunes.  lost 464,000 subscribers   fourth quarter profits  lower    preceding  quarters. ,  company  aol underlying profit  exceptional items rose 8%     stronger internet advertising revenues.  hopes  increase subscribers  offering  online service free  timewarner internet customers     sign  aol existing customers  high-speed broadband. timewarner    restate 2000  2003    probe    securities exchange commission (),   close  concluding.\\n\\ntime warner fourth quarter profits     analysts\\' expectations.   film division  profits slump 27%  $284m, helped  box-office flops alexander  catwoman,  sharp contrast  year-earlier,     final film   lord   rings trilogy boosted .   full-year, timewarner posted  profit  $3.36bn,  27%   2003 performance,  revenues grew 6.4%  $42.09bn. \" financial performance  strong, meeting  exceeding    full-year objectives  greatly enhancing  flexibility,\" chairman  chief executive richard parsons .  2005, timewarner  projecting operating earnings growth   5%,   expects higher revenue  wider profit margins.\\n\\ntimewarner   restate  accounts    efforts  resolve  inquiry  aol   market regulators.    offered  pay $300m  settle charges,   deal    review   .  company    unable  estimate  amount  needed  set   legal reserves,    set  $500m.  intends  adjust    accounts   deal  german music publisher bertelsmann purchase   stake  aol europe,    reported  advertising revenue.    book  sale   stake  aol europe   loss      stake.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Content_parsed_3'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing Punctuation Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation signs\n",
    "data[\"Content_parsed_4\"] = data[\"Content_parsed_3\"]\n",
    "punct_signs = [ \"'\", '\"' , '“' , '”' , \"\\n\" , \"(\" , \")\" , \",\" , \".\" , \"?\", \"-\", \":\"]\n",
    "for sign in punct_signs:\n",
    "    data[\"Content_parsed_4\"] = data[\"Content_parsed_4\"].str.replace(sign, \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit  quarterly profits   media giant timewarner jumped 76%  $1 13bn  â£600m     months  december   $639m year earlier    firm        biggest investors  google  benefited  sales  high speed internet connections  higher advert sales  timewarner  fourth quarter sales rose 2%  $11 1bn  $10 9bn   profits  buoyed    gains  offset  profit dip  warner bros    users  aol   time warner   friday    owns 8%  search engine google     internet business  aol    mixed fortunes   lost 464 000 subscribers   fourth quarter profits  lower    preceding  quarters     company  aol underlying profit  exceptional items rose 8%     stronger internet advertising revenues   hopes  increase subscribers  offering  online service free  timewarner internet customers     sign  aol existing customers  high speed broadband  timewarner    restate 2000  2003    probe    securities exchange commission       close  concluding   time warner fourth quarter profits     analysts  expectations    film division  profits slump 27%  $284m  helped  box office flops alexander  catwoman   sharp contrast  year earlier      final film   lord   rings trilogy boosted     full year  timewarner posted  profit  $3 36bn   27%   2003 performance   revenues grew 6 4%  $42 09bn    financial performance  strong  meeting  exceeding    full year objectives  greatly enhancing  flexibility   chairman  chief executive richard parsons    2005  timewarner  projecting operating earnings growth   5%    expects higher revenue  wider profit margins   timewarner   restate  accounts    efforts  resolve  inquiry  aol   market regulators     offered  pay $300m  settle charges    deal    review      company    unable  estimate  amount  needed  set   legal reserves     set  $500m   intends  adjust    accounts   deal  german music publisher bertelsmann purchase   stake  aol europe     reported  advertising revenue     book  sale   stake  aol europe   loss      stake  '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Content_parsed_4\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    #Map POS tag to first character lemmatize() accepts\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "             \"N\": wordnet.NOUN,\n",
    "             \"V\": wordnet.VERB,\n",
    "             \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmitization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "all_articles = data[\"Content_parsed_4\"]\n",
    "all_articles_l = []\n",
    "for article in all_articles:\n",
    "    article_words = article.split()\n",
    "    article_words_l = []\n",
    "    for article_word in article_words:\n",
    "        article_words_l.append(lemmatizer.lemmatize(article_word, pos = get_wordnet_pos(article_word)))\n",
    "    article_l = \" \".join(article_words_l)\n",
    "    all_articles_l.append(article_l)\n",
    "data[\"Content_parsed_5\"] = all_articles_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sale boost time warner profit quarterly profit medium giant timewarner jumped 76% $1 13bn â£600m month december $639m year earlier firm big investor google benefit sale high speed internet connection high advert sale timewarner fourth quarter sale rise 2% $11 1bn $10 9bn profit buoyed gain offset profit dip warner bros user aol time warner friday own 8% search engine google internet business aol mixed fortune lose 464 000 subscriber fourth quarter profit low precede quarter company aol underlie profit exceptional item rise 8% strong internet advertising revenue hope increase subscriber offering online service free timewarner internet customer sign aol exist customer high speed broadband timewarner restate 2000 2003 probe security exchange commission close conclude time warner fourth quarter profit analyst expectation film division profit slump 27% $284m help box office flop alexander catwoman sharp contrast year earlier final film lord ring trilogy boost full year timewarner post profit $3 36bn 27% 2003 performance revenue grow 6 4% $42 09bn financial performance strong meeting exceed full year objective greatly enhance flexibility chairman chief executive richard parson 2005 timewarner project operating earnings growth 5% expect high revenue wider profit margin timewarner restate account effort resolve inquiry aol market regulator offer pay $300m settle charge deal review company unable estimate amount need set legal reserve set $500m intend adjust account deal german music publisher bertelsmann purchase stake aol europe report advertising revenue book sale stake aol europe loss stake'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Content_parsed_5\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_parsed_1</th>\n",
       "      <th>Content_parsed_2</th>\n",
       "      <th>Content_parsed_3</th>\n",
       "      <th>Content_parsed_4</th>\n",
       "      <th>Content_parsed_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sales boost time warner profit\\n\\nquarterly...</td>\n",
       "      <td>ad sales boost time warner profit\\n\\nquarterly...</td>\n",
       "      <td>ad sales boost time warner profit\\n\\nquarterly...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gains on greenspan speech\\n\\nthe dollar...</td>\n",
       "      <td>dollar gains on greenspan speech\\n\\nthe dollar...</td>\n",
       "      <td>dollar gains  greenspan speech\\n\\n dollar  hit...</td>\n",
       "      <td>dollar gains  greenspan speech   dollar  hit  ...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer faces loan claim\\n\\nthe owner...</td>\n",
       "      <td>yukos unit buyer faces loan claim\\n\\nthe owner...</td>\n",
       "      <td>yukos unit buyer faces loan claim\\n\\n owners  ...</td>\n",
       "      <td>yukos unit buyer faces loan claim   owners  em...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel prices hit ba's profits\\n\\nbritish a...</td>\n",
       "      <td>high fuel prices hit ba profits\\n\\nbritish air...</td>\n",
       "      <td>high fuel prices hit ba profits\\n\\nbritish air...</td>\n",
       "      <td>high fuel prices hit ba profits  british airwa...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lifts domecq\\n\\nshares in...</td>\n",
       "      <td>pernod takeover talk lifts domecq\\n\\nshares in...</td>\n",
       "      <td>pernod takeover talk lifts domecq\\n\\nshares  u...</td>\n",
       "      <td>pernod takeover talk lifts domecq  shares  uk ...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc_name  Category                                            Content  \\\n",
       "0  001.txt  Business  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  002.txt  Business  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  003.txt  Business  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  004.txt  Business  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  005.txt  Business  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                    Content_parsed_1  \\\n",
       "0  ad sales boost time warner profit\\n\\nquarterly...   \n",
       "1  dollar gains on greenspan speech\\n\\nthe dollar...   \n",
       "2  yukos unit buyer faces loan claim\\n\\nthe owner...   \n",
       "3  high fuel prices hit ba's profits\\n\\nbritish a...   \n",
       "4  pernod takeover talk lifts domecq\\n\\nshares in...   \n",
       "\n",
       "                                    Content_parsed_2  \\\n",
       "0  ad sales boost time warner profit\\n\\nquarterly...   \n",
       "1  dollar gains on greenspan speech\\n\\nthe dollar...   \n",
       "2  yukos unit buyer faces loan claim\\n\\nthe owner...   \n",
       "3  high fuel prices hit ba profits\\n\\nbritish air...   \n",
       "4  pernod takeover talk lifts domecq\\n\\nshares in...   \n",
       "\n",
       "                                    Content_parsed_3  \\\n",
       "0  ad sales boost time warner profit\\n\\nquarterly...   \n",
       "1  dollar gains  greenspan speech\\n\\n dollar  hit...   \n",
       "2  yukos unit buyer faces loan claim\\n\\n owners  ...   \n",
       "3  high fuel prices hit ba profits\\n\\nbritish air...   \n",
       "4  pernod takeover talk lifts domecq\\n\\nshares  u...   \n",
       "\n",
       "                                    Content_parsed_4  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "1  dollar gains  greenspan speech   dollar  hit  ...   \n",
       "2  yukos unit buyer faces loan claim   owners  em...   \n",
       "3  high fuel prices hit ba profits  british airwa...   \n",
       "4  pernod takeover talk lifts domecq  shares  uk ...   \n",
       "\n",
       "                                    Content_parsed_5  \n",
       "0  ad sale boost time warner profit quarterly pro...  \n",
       "1  dollar gain greenspan speech dollar hit high l...  \n",
       "2  yukos unit buyer face loan claim owner embattl...  \n",
       "3  high fuel price hit ba profit british airway b...  \n",
       "4  pernod takeover talk lift domecq share uk drin...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Label Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\"Business\" : 0,\n",
    "                 \"Entertainment\" : 1,\n",
    "                 \"Politics\" : 2,\n",
    "                 \"Sport\": 3,\n",
    "                 \"Tech\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Category_codes\"] = data.Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Category_codes = data.Category_codes.replace(category_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_parsed_1</th>\n",
       "      <th>Content_parsed_2</th>\n",
       "      <th>Content_parsed_3</th>\n",
       "      <th>Content_parsed_4</th>\n",
       "      <th>Content_parsed_5</th>\n",
       "      <th>Category_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>Tech</td>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>bt program to beat dialler scams\\n\\nbt is intr...</td>\n",
       "      <td>bt program to beat dialler scams\\n\\nbt is intr...</td>\n",
       "      <td>bt program  beat dialler scams\\n\\nbt  introduc...</td>\n",
       "      <td>bt program  beat dialler scams  bt  introducin...</td>\n",
       "      <td>bt program beat dialler scam bt introduce init...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>spam e-mails tempt net shoppers\\n\\ncomputer us...</td>\n",
       "      <td>spam e-mails tempt net shoppers\\n\\ncomputer us...</td>\n",
       "      <td>spam -mails tempt net shoppers\\n\\ncomputer use...</td>\n",
       "      <td>spam  mails tempt net shoppers  computer users...</td>\n",
       "      <td>spam mail tempt net shopper computer user cont...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>be careful how you code\\n\\na new european dire...</td>\n",
       "      <td>be careful how you code\\n\\na new european dire...</td>\n",
       "      <td>careful   code\\n\\n  european directive   soft...</td>\n",
       "      <td>careful   code    european directive   softwa...</td>\n",
       "      <td>careful code european directive software write...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>Tech</td>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>us cyber security chief resigns\\n\\nthe man mak...</td>\n",
       "      <td>us cyber security chief resigns\\n\\nthe man mak...</td>\n",
       "      <td>cyber security chief resigns\\n\\n man making  ...</td>\n",
       "      <td>cyber security chief resigns   man making   c...</td>\n",
       "      <td>cyber security chief resigns man make computer...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>losing yourself in online gaming\\n\\nonline rol...</td>\n",
       "      <td>losing yourself in online gaming\\n\\nonline rol...</td>\n",
       "      <td>losing   online gaming\\n\\nonline role playing ...</td>\n",
       "      <td>losing   online gaming  online role playing ga...</td>\n",
       "      <td>lose online game online role play game time co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doc_name Category                                            Content  \\\n",
       "2221  397.txt     Tech  BT program to beat dialler scams\\n\\nBT is intr...   \n",
       "2222  398.txt     Tech  Spam e-mails tempt net shoppers\\n\\nComputer us...   \n",
       "2223  399.txt     Tech  Be careful how you code\\n\\nA new European dire...   \n",
       "2224  400.txt     Tech  US cyber security chief resigns\\n\\nThe man mak...   \n",
       "2225  401.txt     Tech  Losing yourself in online gaming\\n\\nOnline rol...   \n",
       "\n",
       "                                       Content_parsed_1  \\\n",
       "2221  bt program to beat dialler scams\\n\\nbt is intr...   \n",
       "2222  spam e-mails tempt net shoppers\\n\\ncomputer us...   \n",
       "2223  be careful how you code\\n\\na new european dire...   \n",
       "2224  us cyber security chief resigns\\n\\nthe man mak...   \n",
       "2225  losing yourself in online gaming\\n\\nonline rol...   \n",
       "\n",
       "                                       Content_parsed_2  \\\n",
       "2221  bt program to beat dialler scams\\n\\nbt is intr...   \n",
       "2222  spam e-mails tempt net shoppers\\n\\ncomputer us...   \n",
       "2223  be careful how you code\\n\\na new european dire...   \n",
       "2224  us cyber security chief resigns\\n\\nthe man mak...   \n",
       "2225  losing yourself in online gaming\\n\\nonline rol...   \n",
       "\n",
       "                                       Content_parsed_3  \\\n",
       "2221  bt program  beat dialler scams\\n\\nbt  introduc...   \n",
       "2222  spam -mails tempt net shoppers\\n\\ncomputer use...   \n",
       "2223   careful   code\\n\\n  european directive   soft...   \n",
       "2224   cyber security chief resigns\\n\\n man making  ...   \n",
       "2225  losing   online gaming\\n\\nonline role playing ...   \n",
       "\n",
       "                                       Content_parsed_4  \\\n",
       "2221  bt program  beat dialler scams  bt  introducin...   \n",
       "2222  spam  mails tempt net shoppers  computer users...   \n",
       "2223   careful   code    european directive   softwa...   \n",
       "2224   cyber security chief resigns   man making   c...   \n",
       "2225  losing   online gaming  online role playing ga...   \n",
       "\n",
       "                                       Content_parsed_5  Category_codes  \n",
       "2221  bt program beat dialler scam bt introduce init...               4  \n",
       "2222  spam mail tempt net shopper computer user cont...               4  \n",
       "2223  careful code european directive software write...               4  \n",
       "2224  cyber security chief resigns man make computer...               4  \n",
       "2225  lose online game online role play game time co...               4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_hold = ['Doc_name', 'Category', 'Content', 'Content_parsed_5', 'Category_codes']\n",
    "data = data[columns_to_hold].rename(columns = {\"Content_parsed_5\" : \"Content_parsed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_parsed</th>\n",
       "      <th>Category_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc_name  Category                                            Content  \\\n",
       "0  001.txt  Business  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  002.txt  Business  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  003.txt  Business  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  004.txt  Business  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  005.txt  Business  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                      Content_parsed  Category_codes  \n",
       "0  ad sale boost time warner profit quarterly pro...               0  \n",
       "1  dollar gain greenspan speech dollar hit high l...               0  \n",
       "2  yukos unit buyer face loan claim owner embattl...               0  \n",
       "3  high fuel price hit ba profit british airway b...               0  \n",
       "4  pernod takeover talk lift domecq share uk drin...               0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train-Test Split   \n",
    "We will keep the test size as only 0.15. Dring training, we will also use cross-validation to get more realistic accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Content_parsed\"], data[\"Category_codes\"], \n",
    "                                                    test_size=0.25, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1669,)    y_train shape: (1669,)\n",
      "X_test shape: (557,)      y_test shape: (557,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"X_train shape: {0}    y_train shape: {1}\n",
    "X_test shape: {2}      y_test shape: {3}\"\"\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train value count:\n",
      " 0    395\n",
      "3    373\n",
      "2    318\n",
      "4    304\n",
      "1    279\n",
      "Name: Category_codes, dtype: int64\n",
      "y_test value count:\n",
      " 3    138\n",
      "0    116\n",
      "1    107\n",
      "2     99\n",
      "4     97\n",
      "Name: Category_codes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train value count:\\n\" ,y_train.value_counts())\n",
    "print(\"y_test value count:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost equal distribution of all categories. Hence **balanced** training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Text Representation using TFIDF \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF parameters used:\n",
    "1. ngram_range = (1, 2)    \n",
    "    We want to capture unigrams and bigrams to capture important words as well as words that appear together\n",
    "2. Minimum df = 10   \n",
    "    To get rid of words that appear extremely rarely in less than 10 documents\n",
    "3. Maximum df = 1.   \n",
    "    No limit to this as this more frequently occuring words will help in classification\n",
    "4. max_features = 300   \n",
    "    Considering top 300 features for building the vocabulary dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(lowercase=False, \n",
    "                         stop_words=None, \n",
    "                         ngram_range=ngram_range, \n",
    "                         max_df=max_df, \n",
    "                         min_df=min_df,\n",
    "                        max_features= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=False, max_df=1.0, max_features=300,\n",
       "                min_df=10, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = tfidf2.transform(X_train)\n",
    "labels_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = tfidf2.transform(X_test)\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Chi-squared test on Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category = Business\n",
      "\n",
      "5 most dependent unigrams: ['firm', 'company', 'share', 'economy', 'bank', 'growth', 'oil']\n",
      "5 most dependent bigrams: ['prime minister', 'told bbc']\n",
      "\n",
      "Category = Entertainment\n",
      "\n",
      "5 most dependent unigrams: ['music', 'song', 'band', 'actor', 'star', 'award', 'film']\n",
      "5 most dependent bigrams: ['told bbc', 'prime minister']\n",
      "\n",
      "Category = Politics\n",
      "\n",
      "5 most dependent unigrams: ['lord', 'mp', 'election', 'blair', 'tory', 'party', 'labour']\n",
      "5 most dependent bigrams: ['told bbc', 'prime minister']\n",
      "\n",
      "Category = Sport\n",
      "\n",
      "5 most dependent unigrams: ['player', 'england', 'win', 'injury', 'champion', 'match', 'cup']\n",
      "5 most dependent bigrams: ['told bbc', 'prime minister']\n",
      "\n",
      "Category = Tech\n",
      "\n",
      "5 most dependent unigrams: ['phone', 'microsoft', 'technology', 'computer', 'mobile', 'user', 'software']\n",
      "5 most dependent bigrams: ['told bbc', 'prime minister']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_dict = {\"Business\" : 0,\n",
    "                \"Entertainment\" : 1,\n",
    "                \"Politics\" : 2,\n",
    "                \"Sport\" : 3,\n",
    "                \"Tech\" : 4}\n",
    "\n",
    "for category, category_id in category_dict.items():\n",
    "    chi2_features = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(chi2_features[0])\n",
    "    feature_names = np.array(tfidf2.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split()) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split()) == 2]\n",
    "    print(\"Category = \" + category + \"\\n\")\n",
    "    print(\"5 most dependent unigrams: \" + str(unigrams[-7:]))\n",
    "    print(\"5 most dependent bigrams: \" + str(bigrams[-2:])+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : It is sensible to say that the unigrams captured corresponding to each category are apt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Pickles\\\\X_train.pickle\", \"wb\") as file:\n",
    "    pickle.dump(X_train, file)\n",
    "\n",
    "with open(\"Pickles\\\\X_test.pickle\", \"wb\") as file:\n",
    "    pickle.dump(X_test, file)\n",
    "    \n",
    "with open(\"Pickles\\\\y_train.pickle\", \"wb\") as file:\n",
    "    pickle.dump(y_train, file)\n",
    "\n",
    "with open(\"Pickles\\\\y_test.pickle\", \"wb\") as file:\n",
    "    pickle.dump(y_test, file)\n",
    "    \n",
    "with open(\"Pickles\\\\features_train.pickle\", \"wb\") as file:\n",
    "    pickle.dump(features_train, file)\n",
    "    \n",
    "with open(\"Pickles\\\\features_test.pickle\", \"wb\") as file:\n",
    "    pickle.dump(features_test, file)\n",
    "    \n",
    "with open(\"Pickles\\\\labels_train.pickle\", \"wb\") as file:\n",
    "    pickle.dump(labels_train, file)\n",
    "    \n",
    "with open(\"Pickles\\\\labels_test.pickle\", \"wb\") as file:\n",
    "    pickle.dump(labels_test, file)\n",
    "    \n",
    "with open(\"Pickles\\\\tfidf.pickle\", \"wb\") as file:\n",
    "    pickle.dump(tfidf2, file)\n",
    "    \n",
    "with open(\"Pickles\\\\data.pickle\", \"wb\") as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
